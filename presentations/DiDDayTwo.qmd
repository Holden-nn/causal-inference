---
title: "Difference In Differences Coding Example"
author: "Holden Nielson"
title-slide-attributes:
  data-background-color: "#486790"
format: 
  revealjs:
    theme: marc.scss     # Modified simple theme.
    slide-number: c/t    # Numbered slides current/total.
    self-contained: true # Required to display ../figures/.
---

## Order of Presentation

- Model we'll be implementing
  - What our model will look like theoretically
- Generating Synthetic Dataset
- Coding our Model in PYMC
- Inference on our Model

## Recall Our Dag for DiD

![](../figures/DiD_dagB.png)

## The Model We'll Be Implementing

$$
\hat{Y_i} = \beta_0 + (\beta_\Delta \times group_i) + (\text{trend} \times t_i) + \\(\Delta \times treated_i \times group_i)
$$


- Where:
  - Parameters:
    - $\beta_0$ is the intercept of the 'control' group
    - $\beta_\Delta$ is difference in 'treatment' intercept vs 'control' intercept
    - $\text{trend}$ is the slope of *both* lines
    - $\Delta$ is the immediate casual impact of treatment

---

$$
\hat{Y_i} = \beta_0 + (\beta_\Delta \times group_i) + (\text{trend} \times t_i) + \\(\Delta \times treated_i \times group_i)
$$

- Where:
  - Observed Data:
    - $t_i$ is time – for this implementation either $t=0$ or $t=1$
    - $group_i$ is a dummy which equal 1 for 'treatment' and 0 for 'control'
    - $treated_i$ is a dummy which equals 1 when an observation occurs within treatment group after the treatment time


---

## What our Model Will Look Like

![](../figures/DiD_Visualization_of_Example_Model.png)


## Outcomes for our Dataset

```{.python}
def outcome(t, control_intercept, treat_intercept_delta, trend, delta, group, treated):
    return control_intercept + (treat_intercept_delta * group) + (t * trend) + (delta * treated * group)

def is_treated(t, intervention_time, group):
    return (t > intervention_time) * group

# true parameters
control_intercept = 1
treat_intercept_delta = 0.25
trend = 1
deltap = 0.5
intervention_time = 0.5
```



## Generating our Synthetic Dataset

```{.python}
df = pd.DataFrame(
    {
        "group": [0, 0, 1, 1] * 10,
        "t": [0.0, 1.0, 0.0, 1.0] * 10,
        "unit": np.concatenate([[i] * 2 for i in range(20)]),
    }
)

df["treated"] = is_treated(df["t"], intervention_time, df["group"])

df["y"] = outcome(
    df["t"],
    control_intercept,
    treat_intercept_delta,
    trend,
    deltap,
    df["group"],
    df["treated"],
)
df["y"] += np.random.normal(0, 0.1)
df.head()
```

## Finding Diff in Diff w/o Regression

```{.python}
diff_control = (
    df.loc[(df["t"] == 1) & (df["group"] == 0)]["y"].mean()
    - df.loc[(df["t"] == 0) & (df["group"] == 0)]["y"].mean()
)
print(f"Pre/post difference in control group = {diff_control:.2f}")

diff_treat = (
    df.loc[(df["t"] == 1) & (df["group"] == 1)]["y"].mean()
    - df.loc[(df["t"] == 0) & (df["group"] == 1)]["y"].mean()
)

print(f"Pre/post difference in treatment group = {diff_treat:.2f}")

diff_in_diff = diff_treat - diff_control
print(f"Difference in differences = {diff_in_diff:.2f}")
```

---

- Pre/post difference in control group = 1.06
- Pre/post difference in treatment group = 1.52
- Difference in differences = 0.46

\

- These Estimates do not have the benefits of being Bayesian posteriors



---

## Coding our Bayesian PYMC Model

```{.python}
with pm.Model() as model:
    # data
    t = pm.Data("t", df["t"].values, dims="obs_idx")
    treated = pm.Data("treated", df["treated"].values, dims="obs_idx")
    group = pm.Data("group", df["group"].values, dims="obs_idx")
    # priors
    _control_intercept = pm.Normal("control_intercept", 0, 5)
    _treat_intercept_delta = pm.Normal("treat_intercept_delta", 0, 1)
    _trend = pm.Normal("trend", 0, 5)
    _deltap = pm.Normal("deltap", 0, 1)
    sigma = pm.HalfNormal("sigma", 1)
    # expectation
    mu = pm.Deterministic(
        "mu",
        outcome(t, _control_intercept, _treat_intercept_delta, _trend, _Δ, group, treated),
        dims="obs_idx",
    )
    # likelihood
    pm.Normal("obs", mu, sigma, observed=df["y"].values, dims="obs_idx")
```

## Performing inference on our model

```{.python}
with model:
    idata = pm.sample()
```

```{.python}
az.plot_trace(idata, var_names="~mu");
```